{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Redes neuronales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### qué es una red neuronal?\n",
    "\n",
    "Una red neuronal es un modelo de aprendizaje automático inspirado en el cerebro humano. \n",
    "\n",
    "- Las neuronas artificiales (nodos) están conectadas entre sí y transmiten señales entre sí.\n",
    "- Las redes neuronales se utilizan para resolver problemas de clasificación y regresión.\n",
    "- Las redes neuronales se pueden utilizar para resolver problemas de clasificación y regresión.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Su origen se remonta a los años 40, cuando McCulloch y Pitts publicaron un artículo sobre cómo una neurona podría modelarse matemáticamente. \n",
    "\n",
    "En 1958, Frank Rosenblatt introdujo el perceptrón, un modelo computacional de una sola capa que se comporta de manera similar a una neurona en el cerebro humano.\n",
    "\n",
    "En 1969, Marvin Minsky y Seymour Papert publicaron un libro titulado \"Perceptrones\", que demostraba las limitaciones del perceptrón y la imposibilidad de resolver problemas no lineales.\n",
    "\n",
    "En 1986, Rumelhart, Hinton y Williams publicaron un artículo que describe un método de entrenamiento para redes neuronales multicapa llamado retropropagación. Este método de entrenamiento permitió que las redes neuronales multicapa se entrenaran con éxito y se convirtieran en el estado del arte para el aprendizaje automático.\n",
    "\n",
    "En 1997, el profesor Schmidhuber introdujo una variante de la retropropagación llamada LSTM (Long Short Term Memory), que se utiliza para resolver problemas de secuencia.\n",
    "\n",
    "En 2012, Alex Krizhevsky ganó el concurso ImageNet utilizando una red neuronal convolucional profunda.\n",
    "\n",
    "En 2014, Google Brain publicó un artículo que describe una red neuronal profunda llamada Red neuronal de Google, que se utilizó para resolver problemas de visión por computadora.\n",
    "\n",
    "En 2015, Microsoft ganó el concurso ImageNet utilizando una red neuronal profunda llamada ResNet.\n",
    "\n",
    "En 2016, AlphaGo de Google DeepMind derrotó al campeón mundial de Go Lee Sedol.\n",
    "\n",
    "En 2017, AlphaGo Zero de Google DeepMind derrotó a AlphaGo 100-0.\n",
    "\n",
    "En 2018, AlphaZero de Google DeepMind derrotó a AlphaGo Zero 100-0.\n",
    "\n",
    "En 2019, AlphaStar de Google DeepMind derrotó a los mejores jugadores de StarCraft II.\n",
    "\n",
    "En 2020, AlphaFold de Google DeepMind resolvió el problema de la predicción de la estructura de la proteína.\n",
    "\n",
    "En 2021, AlphaFold de Google DeepMind resolvió el problema de la predicción de la estructura de la proteína."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Componentes de una neurona normal.\n",
    "\n",
    "- Dendritas: reciben señales de otras neuronas.\n",
    "  \n",
    "- Núcleo: procesa señales recibidas.\n",
    "- axón: transmite señales a otras neuronas.\n",
    "- Sinapsis: punto de conexión entre dos neuronas.\n",
    "- Axón terminal: transmite señales a otras neuronas.\n",
    "- Vesículas: contienen neurotransmisores.\n",
    "- Neurotransmisores: transmiten señales a otras neuronas.\n",
    "- Mielina: aísla el axón y aumenta la velocidad de transmisión de señales.\n",
    "- Nodos de Ranvier: permiten que las señales salten de un nodo a otro.\n",
    "- Cuerpo celular: contiene el núcleo y otras partes de la célula.\n",
    "- Núcleo: contiene el ADN de la célula.\n",
    "- Dendritas: reciben señales de otras neuronas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# componentes de una neurona?\n",
    "\n",
    "- Entradas: son los valores de entrada de la neurona.\n",
    "- Pesos: son los valores que se multiplican por las entradas.\n",
    "- Función de activación: es una función que toma la suma ponderada de las entradas y los pesos y devuelve un valor de salida.\n",
    "- Salida: es el valor de salida de la neurona.\n",
    "- Función de costo: es una función que mide el error entre la salida de la neurona y el valor objetivo.\n",
    "- Función de optimización: es una función que actualiza los pesos de la neurona para reducir el error.\n",
    "- Función de predicción: es una función que toma las entradas y devuelve la salida de la neurona.\n",
    "- Función de entrenamiento: es una función que toma las entradas y los valores objetivo y actualiza los pesos de la neurona para reducir el error.\n",
    "- Función de evaluación: es una función que toma las entradas y los valores objetivo y devuelve el error de la neurona."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tipos de redes neuronales\n",
    "\n",
    "# crea una tabla con los tipos de redes neuronales y sus caracteristicas\n",
    "\n",
    "| Red neuronal | Características |\n",
    "| --- | --- |\n",
    "| Perceptrón | Una capa de neuronas. |\n",
    "| Red neuronal multicapa | Varias capas de neuronas. |\n",
    "| Red neuronal recurrente | Las neuronas están conectadas entre sí. |\n",
    "| Red neuronal convolucional | Las neuronas están conectadas entre sí. |\n",
    "| Red neuronal profunda | Varias capas de neuronas. |\n",
    "| Red neuronal de memoria a corto plazo | Las neuronas están conectadas entre sí. |\n",
    "| Red neuronal de memoria a largo plazo | Las neuronas están conectadas entre sí. |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tipos de redes neuronales, hibdridas supervisadas y no supervisadas, refuerzo\n",
    "\n",
    "- Red neuronal supervisada: se utiliza para resolver problemas de clasificación y regresión.\n",
    "  \n",
    "- Red neuronal no supervisada: se utiliza para resolver problemas de agrupamiento.\n",
    "- Red neuronal de refuerzo: se utiliza para resolver problemas de toma de decisiones.\n",
    "- Red neuronal híbrida: se utiliza para resolver problemas de clasificación y agrupamiento.\n",
    "- Red neuronal profunda: se utiliza para resolver problemas de clasificación y regresión.\n",
    "- Red neuronal recurrente: se utiliza para resolver problemas de secuencia.\n",
    "- Red neuronal convolucional: se utiliza para resolver problemas de visión por computadora.\n",
    "- Red neuronal de memoria a corto plazo: se utiliza para resolver problemas de secuencia.\n",
    "- Red neuronal de memoria a largo plazo: se utiliza para resolver problemas de secuencia."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Que es deep learning?\n",
    "\n",
    "El aprendizaje profundo es un subcampo del aprendizaje automático que utiliza redes neuronales profundas para resolver problemas de clasificación y regresión. \n",
    "\n",
    "### Como se compone una red neuronal profunda?\n",
    "\n",
    "Una red neuronal profunda está compuesta por varias capas de neuronas. cada capa de neuronas está conectada a la siguiente capa de neuronas. la primera capa de neuronas se llama capa de entrada. la última capa de neuronas se llama capa de salida. las capas intermedias se llaman capas ocultas.\n",
    "\n",
    "### Que busca una red neuronal profunda?\n",
    "\n",
    "Una red neuronal profunda busca una función que mapee las entradas a las salidas. la función se llama función de predicción."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# como aprenden las redes neuronales profunda?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Estructura de una Red Neuronal Profunda: Una red neuronal profunda está compuesta por capas de nodos, también conocidos como neuronas. Estas capas incluyen una capa de entrada, varias capas ocultas, y una capa de salida. Cada neurona en una capa está conectada a las neuronas de la capa siguiente.\n",
    "\n",
    "- Inicialización de Pesos: Al inicio, se asignan valores aleatorios a los pesos de las conexiones entre las neuronas. Estos pesos determinan la importancia de las entradas en la generación de la salida.\n",
    "\n",
    "- Propagación hacia Adelante (Forward Propagation): Durante la propagación hacia adelante, los datos de entrada pasan a través de la red, capa por capa, hasta producir una salida. En cada neurona, se realiza una suma ponderada de las entradas y luego se aplica una función de activación para introducir no linealidades.\n",
    "\n",
    "- Función de Pérdida (Loss Function): La salida de la red se compara con la salida esperada, y se calcula el error usando una función de pérdida. Esta función mide qué tan lejos está la predicción de la red del resultado real.\n",
    "\n",
    "- Propagación hacia Atrás (Backpropagation): Este es un proceso clave en el aprendizaje. Utiliza el error calculado por la función de pérdida para actualizar los pesos de la red. Esto se hace a través del cálculo del gradiente de la función de pérdida respecto a cada peso y ajustando los pesos en la dirección que minimiza el error (esto es conocido como el descenso del gradiente).\n",
    "\n",
    "- Optimización: Se utilizan algoritmos de optimización, como el descenso del gradiente estocástico, para cambiar los pesos y reducir el error. Estos ajustes se realizan iterativamente durante muchas rondas o épocas.\n",
    "\n",
    "- Regularización y Prevención del Sobreajuste: Se emplean técnicas como la regularización (por ejemplo, L1, L2) y el dropout para prevenir el sobreajuste, donde la red aprende a memorizar los datos de entrenamiento en lugar de generalizar a partir de ellos.\n",
    "\n",
    "- Afinamiento y Validación: La red se prueba con un conjunto de datos de validación que no se usó durante el entrenamiento. Esto ayuda a verificar la capacidad de generalización del modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# perceptron simple\n",
    "\n",
    "El perceptrón simple es uno de los conceptos fundamentales en el campo de las redes neuronales y el aprendizaje automático. Fue desarrollado por Frank Rosenblatt en la década de 1950. Es un tipo de clasificador lineal, es decir, un algoritmo que clasifica los datos separándolos con una línea (en dos dimensiones), un plano (en tres dimensiones) o un hiperplano (en más dimensiones). A continuación, describo sus características clave:\n",
    "\n",
    "### Estructura Básica\n",
    "- **Entradas**: El perceptrón recibe múltiples señales de entrada (x1, x2, ..., xn), cada una de las cuales está asociada a un peso (w1, w2, ..., wn). Estas entradas pueden ser características o atributos de los datos que se están clasificando.\n",
    "- **Suma Ponderada**: Calcula una suma ponderada de estas entradas, es decir, cada entrada se multiplica por su peso correspondiente y luego se suman todos los resultados.\n",
    "- **Umbral o Sesgo**: Se añade un valor de sesgo (bias) a la suma ponderada. El sesgo permite ajustar la salida del perceptrón para situaciones en las que todas las entradas son cero o para ajustar el umbral de decisión.\n",
    "- **Función de Activación**: La suma ponderada total se pasa a través de una función de activación. En el caso del perceptrón simple, esta función suele ser una función escalón, que devuelve un valor binario (por ejemplo, 0 o 1) dependiendo de si la entrada supera un cierto umbral.\n",
    "\n",
    "### Proceso de Aprendizaje\n",
    "- **Inicialización**: Los pesos se inicializan típicamente con valores pequeños aleatorios.\n",
    "- **Entrenamiento**: Durante el entrenamiento, el perceptrón toma ejemplos de entrenamiento, uno a la vez, y realiza una predicción. Si la predicción es incorrecta, los pesos se ajustan en la dirección que reduciría el error.\n",
    "- **Regla de Aprendizaje**: La regla de aprendizaje más común para el perceptrón es la regla de aprendizaje de Rosenblatt, que ajusta los pesos en función del error de la predicción y de la tasa de aprendizaje.\n",
    "\n",
    "### Limitaciones\n",
    "- **Linearidad**: La principal limitación del perceptrón simple es que solo puede clasificar datos linealmente separables, debido a su naturaleza lineal.\n",
    "- **Solución Única**: En los casos en que los datos son linealmente separables, el perceptrón garantiza encontrar una solución, pero esta solución no es única.\n",
    "\n",
    "A pesar de sus limitaciones, el perceptrón simple jugó un papel crucial en el desarrollo de redes neuronales más complejas y en el campo del aprendizaje automático, proporcionando la base para algoritmos y modelos más avanzados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funciones de activación.\n",
    "\n",
    "\n",
    "Las funciones de activación son un componente esencial en las redes neuronales, ya que introducen no linealidades en el modelo, permitiendo que la red pueda aprender y modelar relaciones complejas en los datos. Sin las funciones de activación, una red neuronal, sin importar cuántas capas tenga, actuaría como un modelo lineal. Aquí algunas de las funciones de activación más comunes:\n",
    "\n",
    "1. **Función Sigmoide (o Logística)**: \n",
    "   - Fórmula: \\( \\sigma(x) = \\frac{1}{1 + e^{-x}} \\)\n",
    "   - Rango: (0, 1)\n",
    "   - Características: Suave y diferenciable en todo su dominio. Tradicionalmente popular, pero puede causar desvanecimiento del gradiente en capas profundas.\n",
    "\n",
    "2. **Función Tangente Hiperbólica (tanh)**:\n",
    "   - Fórmula: \\( \\tanh(x) = \\frac{2}{1 + e^{-2x}} - 1 \\)\n",
    "   - Rango: (-1, 1)\n",
    "   - Características: Similar a la sigmoide pero centrada en cero. También puede sufrir de desvanecimiento del gradiente en redes profundas.\n",
    "\n",
    "3. **Función de Unidad Lineal Rectificada (ReLU)**:\n",
    "   - Fórmula: \\( \\text{ReLU}(x) = \\max(0, x) \\)\n",
    "   - Rango: [0, ∞)\n",
    "   - Características: Muy popular en redes neuronales profundas. Ayuda a mitigar el problema del desvanecimiento del gradiente y tiene un cálculo más eficiente.\n",
    "\n",
    "4. **Leaky ReLU**:\n",
    "   - Fórmula: \\( \\text{Leaky ReLU}(x) = \\max(0.01x, x) \\)\n",
    "   - Rango: (-∞, ∞)\n",
    "   - Características: Una variante de ReLU que permite un pequeño gradiente cuando la unidad no está activa, lo que puede ayudar a evitar neuronas \"muertas\".\n",
    "\n",
    "5. **Función de Escalón**:\n",
    "   - Fórmula: Es básicamente una función binaria que retorna 0 para cualquier entrada negativa y 1 para cualquier entrada no negativa.\n",
    "   - Rango: {0, 1}\n",
    "   - Características: Útil para problemas de clasificación binaria, aunque raramente se usa en la práctica debido a su naturaleza no diferenciable.\n",
    "\n",
    "6. **Softmax**:\n",
    "   - Fórmula: En un vector \\(x\\) de K dimensiones, \\( \\text{Softmax}(x)_i = \\frac{e^{x_i}}{\\sum_{j=1}^{K} e^{x_j}} \\) para i = 1, ..., K.\n",
    "   - Rango: (0, 1) para cada componente, y la suma total es 1.\n",
    "   - Características: Comúnmente usada en la capa de salida para clasificación multiclase, ya que los resultados pueden interpretarse como probabilidades.\n",
    "\n",
    "7. **Función de Identidad**:\n",
    "   - Fórmula: \\( f(x) = x \\)\n",
    "   - Rango: (-∞, ∞)\n",
    "   - Características: Usada en problemas de regresión donde se requiere un rango de salida no restringido.\n",
    "\n",
    "La elección de la función de activación depende del problema específico y de la arquitectura de la red. ReLU y sus variantes son comúnmente usadas en las capas ocultas de redes neuronales profundas debido a su eficiencia y efectividad. La sigmoide y tanh son más comunes en redes más simples o en situaciones específicas donde su comportamiento limitado es deseable. La función Softmax es la opción estándar para la capa de salida en problemas de clasificación multiclase."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## perceptrón multicapa\n",
    "\n",
    "El perceptrón multicapa (MLP, por sus siglas en inglés MultiLayer Perceptron) es una forma básica de red neuronal artificial que se compone de más de una capa de neuronas y puede abordar problemas que no son linealmente separables, lo que supera una de las principales limitaciones del perceptrón simple. A continuación, te describo sus características principales:\n",
    "\n",
    "### Estructura y Componentes\n",
    "1. **Capas**: \n",
    "   - **Capa de Entrada**: Recibe las señales de entrada (características de los datos).\n",
    "   - **Capas Ocultas**: Una o más capas ocultas donde se realiza la mayor parte del procesamiento a través de combinaciones lineales de las entradas y luego aplicando una función de activación no lineal.\n",
    "   - **Capa de Salida**: Produce la salida final de la red. Para tareas de clasificación, esta capa suele tener tantas neuronas como clases posibles.\n",
    "\n",
    "2. **Neuronas**: Cada neurona en una capa está conectada a todas las neuronas en la capa anterior y posterior, formando una red densamente conectada.\n",
    "\n",
    "3. **Pesos y Sesgos**: Cada conexión entre neuronas tiene un peso asociado, y cada neurona en las capas ocultas y de salida tiene un sesgo.\n",
    "\n",
    "4. **Funciones de Activación**: Se utilizan para introducir no linealidades en el modelo, permitiendo que la red aprenda relaciones complejas. Funciones comunes incluyen ReLU, sigmoid y tanh.\n",
    "\n",
    "### Proceso de Aprendizaje\n",
    "1. **Propagación hacia Adelante (Forward Propagation)**: \n",
    "   - Los datos de entrada pasan a través de la red, de capa en capa.\n",
    "   - En cada neurona, se realiza una suma ponderada de las entradas y se aplica la función de activación.\n",
    "\n",
    "2. **Cálculo del Error**:\n",
    "   - Se compara la salida de la red con la salida esperada y se calcula el error.\n",
    "\n",
    "3. **Propagación hacia Atrás (Backpropagation)**: \n",
    "   - Se utiliza el error para calcular el gradiente del error respecto a cada peso en la red.\n",
    "   - Se ajustan los pesos y sesgos para minimizar el error, utilizando técnicas de optimización como el descenso del gradiente.\n",
    "\n",
    "4. **Actualización de Pesos y Sesgos**: \n",
    "   - Se realiza típicamente de manera iterativa durante múltiples épocas o pasadas a través del conjunto de entrenamiento completo.\n",
    "\n",
    "### Aplicaciones y Limitaciones\n",
    "- **Aplicaciones**: El MLP es adecuado para una variedad de tareas, incluyendo clasificación, regresión y reconocimiento de patrones.\n",
    "- **Limitaciones**: Aunque poderosos, los MLP pueden ser propensos al sobreajuste, especialmente en redes con muchas capas y neuronas. Requieren una cuidadosa selección de parámetros, como el número de capas y neuronas, y el método de regularización.\n",
    "\n",
    "El perceptrón multicapa es un concepto fundamental en el aprendizaje profundo y ha sentado las bases para el desarrollo de arquitecturas de red neuronal más complejas y avanzadas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  funciones de costo\n",
    "\n",
    "\n",
    "## Descenso del gradiente\n",
    "\n",
    "El descenso del gradiente es un algoritmo de optimización fundamental utilizado para encontrar el mínimo de una función. Es ampliamente utilizado en el aprendizaje automático y las redes neuronales para minimizar una función de costo o pérdida, que mide qué tan mal está desempeñándose un modelo en función de sus parámetros.\n",
    "\n",
    "### Conceptos Básicos\n",
    "- **Función de Costo**: Es una función que el algoritmo intentará minimizar. En el contexto del aprendizaje automático, representa el error entre las predicciones del modelo y los datos reales.\n",
    "- **Gradiente**: El gradiente de una función en un punto específico es un vector que apunta en la dirección del mayor incremento de la función. Matemáticamente, es la derivada (o el conjunto de derivadas parciales) de la función de costo con respecto a sus parámetros.\n",
    "- **Paso de Descenso**: Se actualizan los parámetros del modelo en la dirección opuesta al gradiente, lo que lleva a una disminución de la función de costo.\n",
    "\n",
    "### Proceso del Descenso del Gradiente\n",
    "1. **Inicialización**: Los parámetros del modelo (por ejemplo, los pesos en una red neuronal) se inicializan con valores aleatorios.\n",
    "2. **Cálculo del Gradiente**: Se calcula el gradiente de la función de costo con respecto a cada parámetro.\n",
    "3. **Actualización de Parámetros**: Los parámetros se actualizan restando el gradiente multiplicado por la tasa de aprendizaje.\n",
    "   - Fórmula de Actualización: \\( \\theta = \\theta - \\alpha \\cdot \\nabla_\\theta J(\\theta) \\)\n",
    "   - Donde \\( \\theta \\) son los parámetros, \\( \\alpha \\) es la tasa de aprendizaje, y \\( \\nabla_\\theta J(\\theta) \\) es el gradiente de la función de costo \\( J \\) respecto a \\( \\theta \\).\n",
    "4. **Iteración**: Este proceso se repite iterativamente hasta que la función de costo converge a un mínimo, o hasta que se cumplan otros criterios de parada, como un número máximo de iteraciones o un cambio mínimo en la función de costo entre iteraciones.\n",
    "\n",
    "### Variantes del Descenso del Gradiente\n",
    "- **Descenso del Gradiente por Lotes (Batch Gradient Descent)**: Calcula el gradiente usando todo el conjunto de datos. Es computacionalmente costoso pero ofrece una dirección de descenso estable.\n",
    "- **Descenso del Gradiente Estocástico (Stochastic Gradient Descent, SGD)**: Calcula el gradiente para cada ejemplo de entrenamiento. Es más rápido pero más errático en su dirección de descenso.\n",
    "- **Descenso del Gradiente Mini-Lote (Mini-batch Gradient Descent)**: Compromiso entre los dos anteriores, utilizando un subconjunto del conjunto de datos (mini-lote) para calcular el gradiente.\n",
    "\n",
    "### Consideraciones Importantes\n",
    "- **Tasa de Aprendizaje**: Un hiperparámetro crucial que determina el tamaño del paso en cada actualización. Una tasa demasiado alta puede hacer que el algoritmo oscile o incluso diverja, mientras que una tasa demasiado baja puede llevar a una convergencia muy lenta.\n",
    "- **Convergencia**: No hay garantía de encontrar el mínimo global, especialmente en funciones de costo complejas con múltiples mínimos locales.\n",
    "- **Normalización de Datos**: A menudo es beneficioso normalizar o estandarizar los datos de entrada para mejorar el rendimiento y la estabilidad del descenso del gradiente.\n",
    "\n",
    "El descenso del gradiente es la piedra angular de muchos algoritmos de aprendizaje automático, y comprender su funcionamiento es clave para el diseño y la optimización de modelos de aprendizaje profundo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Otras opciones\n",
    "\n",
    "Las funciones de costo (o funciones de pérdida) en el contexto de las redes neuronales y el aprendizaje automático son fundamentales para el proceso de entrenamiento. Estas funciones cuantifican el error entre las predicciones hechas por el modelo y los valores reales de los datos. El objetivo del entrenamiento es minimizar esta función de costo, lo que implica ajustar los parámetros (pesos y sesgos) de la red para reducir la diferencia entre la salida predicha y la salida real. Hay varias funciones de costo que se utilizan comúnmente, cada una adecuada para diferentes tipos de problemas:\n",
    "\n",
    "1. **Error Cuadrático Medio (Mean Squared Error, MSE)**:\n",
    "   - Fórmula: \\( MSE = \\frac{1}{N} \\sum_{i=1}^{N} (y_i - \\hat{y}_i)^2 \\)\n",
    "   - Uso: Comúnmente usada en problemas de regresión.\n",
    "   - Características: Mide el promedio de los cuadrados de los errores, es decir, la diferencia cuadrada entre las predicciones y los valores reales.\n",
    "\n",
    "2. **Error Absoluto Medio (Mean Absolute Error, MAE)**:\n",
    "   - Fórmula: \\( MAE = \\frac{1}{N} \\sum_{i=1}^{N} |y_i - \\hat{y}_i| \\)\n",
    "   - Uso: También se usa en regresión.\n",
    "   - Características: Menos sensible a los outliers en comparación con MSE.\n",
    "\n",
    "3. **Entropía Cruzada Binaria (Binary Cross-Entropy, BCE)**:\n",
    "   - Fórmula: \\( BCE = -\\frac{1}{N} \\sum_{i=1}^{N} [y_i \\log(\\hat{y}_i) + (1 - y_i) \\log(1 - \\hat{y}_i)] \\)\n",
    "   - Uso: Usada en clasificación binaria.\n",
    "   - Características: Mide la diferencia entre dos distribuciones de probabilidad, la predicción y la verdad del suelo.\n",
    "\n",
    "4. **Entropía Cruzada Categórica (Categorical Cross-Entropy)**:\n",
    "   - Fórmula: Similar a la BCE pero extendida a múltiples clases.\n",
    "   - Uso: Clasificación multiclase.\n",
    "   - Características: Aplica la entropía cruzada a cada elemento de la distribución de clases y suma los resultados.\n",
    "\n",
    "5. **Softmax Loss**:\n",
    "   - Combina la función Softmax y la entropía cruzada en una sola función.\n",
    "   - Uso: Clasificación multiclase en redes neuronales profundas.\n",
    "   - Características: Transforma las salidas de la red en una distribución de probabilidad y luego aplica la entropía cruzada.\n",
    "\n",
    "6. **Hinge Loss**:\n",
    "   - Fórmula: \\( Hinge = \\frac{1}{N} \\sum_{i=1}^{N} \\max(0, 1 - y_i \\cdot \\hat{y}_i) \\)\n",
    "   - Uso: Usada en máquinas de vectores de soporte (SVM) y en algunos casos en clasificación.\n",
    "   - Características: Útil para clasificación \"márgenes grandes\" y problemas de clasificación binaria.\n",
    "\n",
    "7. **Huber Loss**:\n",
    "   - Una combinación de MSE y MAE.\n",
    "   - Uso: Regresión, especialmente cuando los datos tienen outliers.\n",
    "   - Características: Menos sensible a los outliers que MSE.\n",
    "\n",
    "La elección de la función de costo depende del tipo específico de problema (regresión, clasificación, etc.) y de las características particulares de los datos y el modelo. El objetivo del entrenamiento es ajustar los parámetros del modelo de manera que se minimice esta función de costo, lo cual se hace típicamente utilizando algoritmos de optimización como el descenso del gradiente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".\n",
    "\n",
    "### Forward Propagation (Propagación hacia Adelante)\n",
    "La propagación hacia adelante es el proceso mediante el cual una red neuronal procesa la información desde la entrada hasta la salida. En cada capa de la red, se realizan dos pasos principales:\n",
    "\n",
    "1. **Combinación Lineal de Entradas**: Cada neurona en una capa recibe entradas de todas las neuronas de la capa anterior (o de los datos de entrada en la primera capa). Estas entradas se combinan de una manera específica determinada por los \"pesos\" de la red, que son valores que indican la importancia o influencia de cada entrada en la neurona.\n",
    "\n",
    "2. **Aplicación de una Función de Activación**: Después de combinar las entradas, cada neurona aplica una función de activación a este valor combinado. Esta función de activación es una operación matemática no lineal que determina la salida de la neurona. La no linealidad es crucial porque permite que la red aprenda y modele relaciones complejas en los datos.\n",
    "\n",
    "Este proceso se repite en cada capa de la red hasta llegar a la capa de salida, donde la red produce su predicción final o salida.\n",
    "\n",
    "### Backpropagation (Retropropagación)\n",
    "La retropropagación es el método que utiliza una red neuronal para aprender y mejorar su rendimiento. Es un proceso de ajuste de los pesos de la red en respuesta al error en la salida. Se realiza después de la propagación hacia adelante y consta de los siguientes pasos:\n",
    "\n",
    "1. **Evaluación del Error**: Primero, se calcula el error, que es la diferencia entre la salida de la red y la salida deseada (la respuesta correcta).\n",
    "\n",
    "2. **Propagación del Error hacia Atrás**: Este error se propaga de vuelta a través de la red, desde la capa de salida hasta la capa de entrada. En cada capa, el error se utiliza para determinar cuánto contribuyó cada neurona al error total.\n",
    "\n",
    "3. **Ajuste de Pesos**: Basándose en cuánto contribuyó cada neurona al error, se ajustan los pesos de la red. Este ajuste se realiza de manera que si una neurona contribuyó mucho al error, su peso se cambia más significativamente. Este proceso utiliza algoritmos de optimización, como el descenso del gradiente, aunque no entremos en detalles matemáticos aquí.\n",
    "\n",
    "4. **Iteración y Aprendizaje**: Este proceso de propagación hacia adelante seguido de la retropropagación se repite muchas veces (en iteraciones o épocas) sobre el conjunto de entrenamiento. Con cada repetición, la red ajusta sus pesos para reducir el error en su salida, aprendiendo efectivamente de los datos.\n",
    "\n",
    "### Resumen\n",
    "En resumen, la propagación hacia adelante es cómo la red neuronal procesa la información para hacer una predicción, y la retropropagación es cómo la red aprende de sus errores para mejorar sus predicciones en el futuro. Este proceso iterativo es la esencia del entrenamiento en el aprendizaje profundo."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
